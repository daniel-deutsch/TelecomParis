{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP_GAN_MNIST.ipynb","provenance":[],"collapsed_sections":["ZArhS5VC7jm1","J62Zz0Tp7Q5R"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OcSwPCs38xgh"},"source":["# Training a GAN\n","\n","In this practical session, we will implement a GAN on the MNIST dataset. SOme parts of the code are missing. Complete the code until you are able to generate images. "]},{"cell_type":"code","metadata":{"id":"Fa0Cc5cs1R6x","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1570613596107,"user_tz":-120,"elapsed":2073,"user":{"displayName":"Stéphane Lathuilière","photoUrl":"","userId":"06153603845847990845"}},"outputId":"6e0a1549-05ef-4321-ed81-3a461e35d656"},"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n","import numpy as np\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import keras\n","\n","from keras.layers import Input\n","from keras.models import Model, Sequential\n","from keras.layers.core import Reshape, Dense, Dropout, Flatten\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import Conv2D, UpSampling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.datasets import mnist\n","from keras.optimizers import Adam\n","from keras import backend as K\n","from keras import initializers\n","import PIL.Image\n","import IPython.display\n","import numpy as np\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["2.2.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UkB0fziq8Cgp"},"source":["## Data processing\n","We load the mnist dataset\n","The 28x28 are flattened. We will consider these images as vectors."]},{"cell_type":"code","metadata":{"id":"WcFybeq71aJC","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1570613602806,"user_tz":-120,"elapsed":8759,"user":{"displayName":"Stéphane Lathuilière","photoUrl":"","userId":"06153603845847990845"}},"outputId":"4a152e33-abe4-4f60-f7f5-e72312aa2b76"},"source":["\n","\n","# The results are a little better when the dimensionality of the random vector is only 10.\n","# The dimensionality has been left at 100 for consistency with other GAN implementations.\n","randomDim = 100\n","\n","# Load MNIST data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_train = (X_train.astype(np.float32) - 127.5)/127.5\n","\n","X_train = X_train.reshape(60000, 784)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZArhS5VC7jm1"},"source":["\n","## Network architectures\n","\n","Specify the encoder and the decoder architectures. Use a few fully connected layers (Dense). Pay attention to the input and output dimensions "]},{"cell_type":"code","metadata":{"id":"Z3JEMO2O1q2Q","colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"status":"error","timestamp":1570613602819,"user_tz":-120,"elapsed":8759,"user":{"displayName":"Stéphane Lathuilière","photoUrl":"","userId":"06153603845847990845"}},"outputId":"1aa1b925-40ca-422d-c18b-22cc1fbb79f3"},"source":["# Optimizer\n","adam = Adam(lr=0.0002, beta_1=0.5)\n","\n","generator = Sequential()\n","# ....\n","#implement a network with 4 FC layers of dimensions 256,512,1024,784 with activations LeakyReLU(0.2),LeakyReLU(0.2),LeakyReLU(0.2),tanh\n","# ....\n","\n","\n","generator.summary()\n","\n","\n","discriminator = Sequential()\n","# ....\n","#implement a network with 4 FC layers of dimensions 1024,512,256,1 with activations LeakyReLU(0.2),LeakyReLU(0.2),LeakyReLU(0.2) and \"?\"\n","# ....\n","\n","discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n","\n","discriminator.summary()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-5da9672f00e9>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    generator.add(Dense(, activation='tanh'))\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"X-Mr4KCO1wNn"},"source":["# We combined the generator and discriminator to create a gan model\n","discriminator.trainable = False\n","ganInput = Input(shape=(randomDim,))\n","#....\n","gan = Model(inputs=ganInput, outputs=ganOutput)\n","gan.compile(loss='binary_crossentropy', optimizer=adam)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J62Zz0Tp7Q5R"},"source":["## Display\n","Some display functions. There is nothing to complete here."]},{"cell_type":"code","metadata":{"id":"8PW52dgS16u4"},"source":["\n","\n","\n","# Plot the loss from each batch\n","def plotLoss(epoch):\n","    plt.figure(figsize=(10, 8))\n","    plt.plot(dLosses, label='Discriminitive loss')\n","    plt.plot(gLosses, label='Generative loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig('gan_loss_epoch_%d.png' % epoch)\n","\n","# Create a wall of generated MNIST images\n","def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n","    noise = np.random.normal(0, 1, size=[examples, randomDim])\n","    generatedImages = generator.predict(noise)\n","    generatedImages = generatedImages.reshape(examples, 28, 28)\n","\n","    plt.figure(figsize=figsize)\n","    for i in range(generatedImages.shape[0]):\n","        plt.subplot(dim[0], dim[1], i+1)\n","        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray')\n","        plt.axis('off')\n","    plt.tight_layout()\n","    plt.savefig('gan_generated_image_epoch_%d.png' % epoch)\n","    IPython.display.display(IPython.display.Image(data=('gan_generated_image_epoch_%d.png' % epoch)))\n","\n","# Save the generator and discriminator networks (and weights) for later use\n","\n","\n","def saveModels(epoch):\n","    generator.save('gan_generator_epoch_%d.h5' % epoch)\n","    discriminator.save('gan_discriminator_epoch_%d.h5' % epoch)\n","    \n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aBeNsHF546Hh"},"source":["## Main loop\n","\n","This is now the main loop of the gan. In each loop, we update first the discriminator and then the generator.\n","\n","Complete the code. Don't forget to specify which networks shoulb be trainable in step of the training loop."]},{"cell_type":"code","metadata":{"id":"bCdN3rAd1PE2"},"source":["\n","dLosses = []\n","gLosses = []\n","\n","\n","epochs=22\n","batchSize=128\n","batchCount = X_train.shape[0] // batchSize\n","print('Epochs:', epochs)\n","print('Batch size:', batchSize)\n","print('Batches per epoch:', batchCount)\n","\n","for e in range(1, epochs+1):\n","    print('-'*15, 'Epoch %d' % e, '-'*15)\n","    for _ in tqdm(range(batchCount)):\n","        ####### Train discriminator #####\n","        \n","\n","        # Get a random set of input noise and images\n","        # Generate fake MNIST images\n","        noise = np.random#...\n","        generatedImages = #...\n","        \n","        #we create a batch composed of real and fake images\n","        imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n","        X = np.concatenate([imageBatch, generatedImages])\n","\n","        \n","        # We manually create the labels corresponding to X (1 for real, 0 for generated)\n","        yDis = #...\n","        \n","        \n","        # Train discriminator to distinguish real and fake\n","        #...\n","        dloss = discriminator.train_on_batch(X, yDis)\n","\n","\n","        ####### Train generator #####\n","        # Generate fake MNIST images\n","        noise = np.random #...\n","        # labels\n","        yGen = #...\n","        # Train generator to confuse the discriminator by forcing the discrimitinator to see the generated images as Real(label=1)\n","\n","        discriminator.trainable = False\n","        gloss = gan.train_on_batch(noise, yGen)\n","\n","    # Store loss of most recent batch from this epoch\n","    dLosses.append(dloss)\n","    gLosses.append(gloss)\n","\n","    if e == 1 or e % 1 == 0:\n","        plotGeneratedImages(e)\n","        saveModels(e)\n","\n","    # Plot losses from every epoch\n","    plotLoss(e)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SBoPJXjq6B2a"},"source":["## DCGAN\n","\n","Save a copy of your colab. Now, we will implement a version of GAN that uses convolutions: DCGAN. You can find the paper [here](https://arxiv.org/abs/1511.06434). Replace your naive generator and decoder by the DCGAN architectures. We recommend to batch normalization before each leaky-relu activations. This is slower to train but by looking at the images after one epoch, you can already draw an interesting conclusion."]}]}