{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_LeNet5_empty.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iafPdtuncbq7"
      },
      "source": [
        "<h2><center>MNIST classification using <i>LeNet5</i></center></h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5er-BvoYKV8"
      },
      "source": [
        "# As a first step, we may want to switch to a GPU-acceperated VM\n",
        "# In the menu: Runtime->Change runtime type->Hardware Accelerator->GPU.\n",
        "#\n",
        "# This will thest if we have a GPU-equipped VM and return some useful system-level information\n",
        "#!nvidia-smi\n",
        "\n",
        "# Which GNU/Linux distribution is installed on our VM ?\n",
        "#!lsb_release -a\n",
        "\n",
        "# Which version of the Linux kernel our VM has ?\n",
        "#!uname -a\n",
        "\n",
        "# How much free memory our VM has ?\n",
        "#!free -h\n",
        "\n",
        "# Which storage facilities our VM has ?\n",
        "#!mount\n",
        "\n",
        "# Which python version our VM has installed ?\n",
        "#!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4VrCB5La5rD"
      },
      "source": [
        "# Importing Keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlKZ3Hnas7B4"
      },
      "source": [
        "# Importing the Keras main module and the tensorflow backend\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "print(\"Using tensorflow version \" + str(tf.__version__))\n",
        "print(\"Using keras version \" + str(keras.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_QLz9_jbRZq"
      },
      "source": [
        "# Loading and preparing the MNIST dataset\n",
        "Load the MNIST dataset made available by keras.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG83hGyVmijn"
      },
      "source": [
        "#@title\n",
        "# The MNSIT dataset is ready to be imported from Keras into RAM\n",
        "# Warning: you cannot do that for larger databases (e.g., ImageNet)\n",
        "from keras.datasets import ...\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYDuAd99Y7oi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsIOoCXmYoya"
      },
      "source": [
        "Let us visualize the first training sample using the Gnuplot library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5geREt4YtpZ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "imageIndex = [...]\n",
        "print(\"Label for \" + str([...]) + \"-th train image is: \" + str(train_labels[...]))\n",
        "plt.imshow([...])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqtZCOxcDS0U"
      },
      "source": [
        "Turn train and test labels to one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQbkllF8mnaf"
      },
      "source": [
        "# The ground truth labels need to be converted to the one-hot encoding format via to_categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTSbzJ8zDi0b"
      },
      "source": [
        "Reshape train and test images so that they follow the NWHC ordering required by the TF backend. Then, after casting the pixels to floats, normalize the images so that they have zero-mean and unitary deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptTRSDo5nJyZ"
      },
      "source": [
        "# We need to reshape to proper images with 1 color channel according to the tensorflow backend NWHC scheme\n",
        "img_rows, img_cols = train_images.shape[1], train_images.shape[2]\n",
        "train_images = train_images.reshape(...)\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "\n",
        "# Casting pixels from uint8 to float32 to allow normalization\n",
        "train_images = train_images.astype('float32')\n",
        "\n",
        "# Now let us normalize the images so that they have zero mean and standard deviation\n",
        "# Hint: are real testing data statistics known at training time ?\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwm1OFOtc4uU"
      },
      "source": [
        "# Defining the neural network architecture (i.e., the network model)\n",
        "Create a LeNet5-like convolutional neural network taking in input the images as matrices of pixels and suitable to classify each image across 10 different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnd3q1V3nk8v"
      },
      "source": [
        "# The Sequential module is sort of a container for more complex NN elements and\n",
        "# defines a loop-less NN architecture\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Convolution2D, MaxPooling2D\n",
        "from keras.layers import ..., ...\n",
        "\n",
        "input_shape = (..., ..., ...)\n",
        "output_shape = ...\n",
        "\n",
        "# size of pooling area for max pooling\n",
        "pool_size = (..., ...)\n",
        "# convolution kernel size\n",
        "kernel_size = (..., ...)\n",
        "# Number of filters in first convolutional layer\n",
        "num_kernel_first_conv_layer = ...\n",
        "# Number of filters in second convolutional layer\n",
        "num_kernel_second_conv_layer = ...\n",
        "\n",
        "# START CODE HERE\n",
        "\n",
        "#First Convolve-and-pool block\n",
        "model.add(Convolution2D([...])\n",
        "model.add(Activation([...])\n",
        "model.add(MaxPooling2D([...])\n",
        "\n",
        "#Second Convolve-and-pool block\n",
        "[...]\n",
        "\n",
        "# Turn the sequence of featuremaps into an array of features\n",
        "[...]\n",
        "\n",
        "# First fully connected hidden layer with 120 neurons\n",
        "[...]\n",
        "\n",
        "# Second fully connected hidden layer with 84 neurons\n",
        "[...]\n",
        "\n",
        "# Output layer: how many neurons and which activation function ?\n",
        "[...]\n",
        "\n",
        "# END CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_QEHUznSMyY"
      },
      "source": [
        "Instantiate a SGD optimizer with a tentative LR of 10^-4 and using the appropriate loss function and compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ParUs_WKSNmZ"
      },
      "source": [
        "# The optimizers module provides a number of optimization algorithms for updating\n",
        "# a netwok parameters accoridng to the computed error gradints\n",
        "from keras import optimizers\n",
        "\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "\n",
        "# Let us have a look at the model topology after compiling the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AWUAW4idF3D"
      },
      "source": [
        "# Training the network\n",
        "Train the model for 10 epochs using the train_on_batch() and test_on_batch() methods, manually cycling through generations and batches od samples.\n",
        "Hint 1: instantiate a ImageDataGenerator() to get an iterator over the samples.\n",
        "Hint 2: store the per-epoch test and train loss and accuracy to plot them later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTHrbb7uFYWz"
      },
      "source": [
        "# This is where the actual training-testing happens\n",
        "# Dimension of the batch size (number of images over which error gradients are averaged)\n",
        "batch_size = 100\n",
        "# Number of epochs we want to train\n",
        "epochs = 10\n",
        "\n",
        "#For being able to plot the training history afterwards\n",
        "history = {}\n",
        "history['loss'] = []\n",
        "history['val_loss'] = []\n",
        "history['acc'] = []\n",
        "history['val_acc'] = []\n",
        "\n",
        "\n",
        "# Creating a batch preprocessor for feeding the train and test data in batches\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "myDatagen = ImageDataGenerator()\n",
        "# Compute quantities required for feature-wise normalization\n",
        "myDatagen.fit(train_images)\n",
        "\n",
        "# Cycling through the epochs\n",
        "for e in range(epochs):\n",
        "    lossEpochTrain = 0\n",
        "    lossEpochTest = 0\n",
        "    accuracyEpochTrain = 0\n",
        "    accuracyEpochTest = 0\n",
        "\n",
        "    # Counter of training batches \n",
        "    batchCnt = 0\n",
        "    # Training over the training samlpes, batch by batch\n",
        "    for images_batch, labels_batch in myDatagen.flow(train_images, train_labels, batch_size=batch_size):\n",
        "        batch_history = model.train_on_batch([...])\n",
        "        # We want to store the train loss and accuracy for each batch \n",
        "        lossEpochTrain += batch_history[...]\n",
        "        accuracyEpochTrain += batch_history[...]\n",
        "        batchCnt += 1\n",
        "        # break the loop or generator loops indefinitely\n",
        "        if batchCnt >= len(train_images) / batch_size:\n",
        "            break\n",
        "\n",
        "    # For the test set, take example from teh train set updating the code as needed\n",
        "    batchCnt = 0\n",
        "    for images_batch, labels_batch in myDatagen.flow(test_images, test_labels, batch_size=batch_size):\n",
        "        # START CODE HERE\n",
        "        ...\n",
        "        # END CODE HERE\n",
        "\n",
        "    print ('Epoch %d / %d lossTrain %.3f lossTest %.3f accuracyTrain %.3f accuracyTest %.3f' %(int(e), epochs, lossEpochTrain/batchCnt, lossEpochTest/batchCnt, accuracyEpochTrain/batchCnt, accuracyEpochTest/batchCnt))\n",
        "    history['loss'].append(lossEpochTrain/batchCnt)\n",
        "    history['val_loss'].append(lossEpochTest/batchCnt)\n",
        "    history['acc'].append(accuracyEpochTrain/batchCnt)\n",
        "    history['val_acc'].append(accuracyEpochTest/batchCnt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODUc5Bq_dMEq"
      },
      "source": [
        "# Visualizing the network performance\n",
        "Visualize the training history using the pyplot package: plot in one graph the train and vaidation loss functions, in another graph the train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdJrRbyariEw"
      },
      "source": [
        "# We now want to plot the train and validation loss functions and accuracy curves\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for accuracy\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr4TdWoEoDzi"
      },
      "source": [
        "# Experiments\n",
        "\n",
        "Note down the performance of the trained network in terms of training and validation accuracy as a reference. Then, experiment as follow and compare performance with the reference scenario.\n",
        "\n",
        "* Modify the network architecture to obtain a twofold reduction of each featuremap size without resorting to pooling layers (hint: take insipiration from the ResNet architecture).\n",
        "* Using the proper metric  from sklearn, check which character is most frequently confused with which: can you explain why ?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0C1J6R1Elfc"
      },
      "source": [
        "# We now want to plot the confusion matrix using sklearn.metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = model.predict(test_images)\n",
        "# Mind that confusion_matrix requires\n",
        "matrix = confusion_matrix(test_labels.argmax(axis=1), predictions.argmax(axis=1))\n",
        "print (matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_WVRm_fMXP"
      },
      "source": [
        "#Saving the training results\n",
        "\n",
        "Save the best trained model (topology, parameters), and all the related side information required to deploy the trained model later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbJCJZ3mfOYu"
      },
      "source": [
        "# Create a directory for saving both the trained model and side information\n",
        "import os\n",
        "save_dir = os.path.join(os.getcwd(), 'trained_lenet5_mnist')\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "# Save model and weights\n",
        "model_name = 'model.h5'\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# Saving mean and standard deviation information as a CSV file\n",
        "import csv\n",
        "# START CODE HERE\n",
        "...\n",
        "# END CODE HERE\n",
        "print('Saved side information at %s ' % model_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}